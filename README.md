# ğŸ§  Intelligent Query Router with Sub-Agents

This project implements an **Intelligent Query Router** that dynamically routes natural language queries to the most relevant data sourceâ€”**SQL** or **RAG (Vector Store)**â€”based on confidence scoring. If both tools fail to confidently respond, the system rephrases and retries the query using an LLM.

---

## ğŸš€ Project Overview

### ğŸ”§ Tools

* **SQL Agent Tool**: LangGraph + LangChain SQL agent wrapped as a tool, executes validated SQL queries over PostgreSQL.
* **RAG Agent Tool**: Embedding-based document retriever (ChromaDB), handles unstructured data (PDFs), exposed as a tool.

### ğŸ§  Router Agents

* **LangChain ReAct Router**: Uses tool-calling logic to choose between SQL and RAG tools.
* **LangGraph Router**:

  * Calls both tools in parallel
  * Scores both responses using heuristics + cross-encoder
  * Picks the best response
  * Optionally rephrases and retries the query

### ğŸ› ï¸ Tool Server (MCP)

Hosts both SQL and RAG tools as callable Model Context Protocol (MCP) endpoints.

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ rag_agent.py              # RAG retrieval agent + tool
â”‚   â”œâ”€â”€ prebuilt_sql_agent.py     # LangGraph SQL agent as a tool
â”‚
â”œâ”€â”€ MCP/
â”‚   â”œâ”€â”€ tools.py                  # Tool loader for SQL & RAG
â”‚   â””â”€â”€ mcp_server.py             # Launches MCP tool server
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ Pdf_embedding.py          # Embeds PDFs to ChromaDB
â”‚   â”œâ”€â”€ setup_postgres.py         # Loads CSV into PostgreSQL
â”‚
â”œâ”€â”€ guardrails/
â”‚   â”œâ”€â”€ sql_guardrails.py         # SQL confidence scoring
â”‚   â””â”€â”€ rag_guardrails.py         # RAG answer scoring
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ sql_prompts.py            # Prompt templates for SQL
â”‚   â””â”€â”€ rag_prompts.py            # Prompt templates for RAG
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_sql.py               # (Do not use)
â”‚   â”œâ”€â”€ test_rag.py               # RAG unit tests
â”‚   â””â”€â”€ test_router.py            # Router integration tests
â”‚
â”œâ”€â”€ gradio_ui/
â”‚   â””â”€â”€ app.py                    # Gradio interface
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ example_run.py            # Optional runner
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ csv_data.csv              # Sample structured data
â”‚   â””â”€â”€ pdf_docs/                 # Sample PDFs
â”‚
â”œâ”€â”€ chroma_db/                    # Chroma vector DB (ignored)
â”œâ”€â”€ .env                          # API keys + DB config
â”œâ”€â”€ requirements.txt              # Project dependencies
â””â”€â”€ README.md                     # You are here
```

---

## ğŸ› ï¸ Setup

### âœ… Create Environment (Python 3.11)

**With Conda:**

```bash
conda create -n agent-router python=3.11 -y
conda activate agent-router
```

**With venv:**

```bash
python3.11 -m venv venv
source venv/bin/activate       # Windows: venv\Scripts\activate
```

---

### âœ… Install Dependencies

```bash
pip install -r requirements.txt
pip install sentence-transformers torch numpy   # (optional scoring models)
```

---

### âœ… Configure `.env`

Create a `.env` file at the root:

```env
DATABASE_URL=postgresql://user:pass@localhost:5432/your_db
OPENAI_API_KEY=sk-...
CE_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
```

---

## âš™ï¸ Running the System

### â–¶ï¸ Step 1: Start MCP Tool Server

```bash
python -m MCP.mcp_server
```

> Keep this terminal open â€” it hosts the tools.

---

### â–¶ï¸ Step 2: Run the Query Router

```bash
python -m agents.router
# Example input:
# â“  Who submitted the compliance report?
```

> Output includes selected tool, answer, and confidence score.

---

### ğŸ–¼ Optional: Launch Gradio UI

```bash
python gradio_ui/app.py
```

> Opens a browser UI for testing the system interactively.

---

## ğŸ” Confidence Scoring Logic

### âœ… 1. SQL Confidence

* **Row volume**: `min(num_rows / 10, 1.0)`
* **Null coverage**: `1 - (null_cells / total_cells)`
* **Cross-encoder**: Similarity over top rows

```python
sql_conf = 0.3 * volume + 0.2 * coverage + 0.5 * encoder
```

---

### âœ… 2. Answer Confidence

* Cross-encoder similarity between question and answer
* Penalizes overly short or long responses
* Checks numeric token alignment

---

### âœ… Final Score

```python
confidence = 0.7 * sql_conf + 0.3 * answer_conf
```

---

## ğŸ§  Architecture Summary

### ğŸ“ƒ SQL Agent (LangGraph)

* Nodes: `list_tables â†’ get_schema â†’ generate â†’ validate â†’ run`
* Exposed via MCP tool server

### ğŸ“„ RAG Agent (LangChain + Chroma)

* Embeds PDF & CSV to vector DB
* Retrieves top-k documents
* Synthesizes answer with LLM

### ğŸ”€ Query Router

1. Try SQL tool â†’ score
2. Try RAG tool â†’ score
3. Pick highest score
4. Rephrase + retry if both are weak

---

## ğŸ§ª Running Tests

Make sure `chroma_db/` and PostgreSQL are preloaded:

```bash
pytest tests/
```

---

## ğŸ“œ License

MIT License â€” see `LICENSE` file for details.
